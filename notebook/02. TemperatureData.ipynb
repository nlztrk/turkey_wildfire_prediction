{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017d6e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlztrk/anaconda3/envs/wildfire/lib/python3.8/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f094929",
   "metadata": {},
   "source": [
    "## Temperature Data\n",
    "\n",
    "We used [Berkeley Earth Global-Warming Dataset](http://berkeleyearth.org/data/). \n",
    "The Berkeley Earth averaging process generates a variety of Output data including a set of gridded temperature fields, regional averages, and bias-corrected station data. Source data consists of the raw temperature reports that form the foundation of our averaging system. Source observations are provided as originally reported and will contain many quality control and redundancy issues. Intermediate data is constructed from the source data by merging redundant records, identifying a variety of quality control problems, and creating monthly averages from daily reports when necessary.\n",
    "\n",
    "The dataset expresses temperatures as anomalies. It determines the average temperature between the years 70-80 as climatology, and the difference to this average temperature in the current date as anomaly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9d0be",
   "metadata": {},
   "source": [
    "## Defining the Target Zone\n",
    "Define the latitude & longitude ranges of your target country, zone, etc. The example is for Turkey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22678c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT_RANGE = (36, 42)\n",
    "LON_RANGE = (26, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b61a1",
   "metadata": {},
   "source": [
    "We are importing the data-paths for min, max and avg temperatures. Defining suffixes for their column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb5a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files_min = [\n",
    "                '../data/raw_data/Complete_TMIN_Daily_LatLong1_2010.nc',\n",
    "                '../data/raw_data/Complete_TMIN_Daily_LatLong1_2020.nc',\n",
    "             ]\n",
    "\n",
    "data_files_max = [\n",
    "                '../data/raw_data/Complete_TMAX_Daily_LatLong1_2010.nc',\n",
    "                '../data/raw_data/Complete_TMAX_Daily_LatLong1_2020.nc',\n",
    "             ]\n",
    "\n",
    "data_files_avg = [\n",
    "                '../data/raw_data/Complete_TAVG_Daily_LatLong1_2010.nc',\n",
    "                '../data/raw_data/Complete_TAVG_Daily_LatLong1_2020.nc',\n",
    "             ]\n",
    "\n",
    "suffixes = [\"_min\", \"_max\", \"_avg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d70629",
   "metadata": {},
   "source": [
    "We are iterating over our temperature datasets. We are only taking the zones that falls within our target latitude & longitude ranges.\n",
    "\n",
    "We have the data on daily basis. We are extracting means from them to create monthly features. We add our 'temperature anomaly' to our 'climatology mean temperature' to find the actual temperature.\n",
    "\n",
    "Finally, we combine the min, max and avg data chronologically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82ab89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/home/nlztrk/anaconda3/envs/wildfire/lib/python3.8/site-packages/xarray/backends/plugins.py:68: RuntimeWarning: Engine 'cfgrib' loading failed:\n",
      "Cannot find the ecCodes library\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:10<00:00,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "temperature_dfs = []\n",
    "\n",
    "\n",
    "for data_i, data_files in enumerate(tqdm([data_files_min, data_files_max, data_files_avg])):\n",
    "    datasets = []\n",
    "\n",
    "    for data_file in data_files:\n",
    "        ds = xr.open_dataset(data_file)\n",
    "\n",
    "        climatology_df = ds[[\"climatology\"]]\n",
    "        climatology_df = climatology_df.where((climatology_df.latitude >= LAT_RANGE[0]) &\\\n",
    "                          (climatology_df.latitude <= LAT_RANGE[1]) &\\\n",
    "                          (climatology_df.longitude >= LON_RANGE[0]) &\\\n",
    "                          (climatology_df.longitude <= LON_RANGE[1]),\n",
    "                      drop=True)\\\n",
    "                      .to_dataframe().reset_index().dropna().rename(columns={\"day_number\":\"day_of_year\"})   \n",
    "        climatology_df = climatology_df.groupby([\"climatology\", \"longitude\", \"latitude\"]).mean().reset_index()\n",
    "\n",
    "        ds = ds[[\"temperature\", \"month\", \"year\", \"day_of_year\"]]\n",
    "        ds = ds.where((ds.latitude >= LAT_RANGE[0]) &\\\n",
    "                      (ds.latitude <= LAT_RANGE[1]) &\\\n",
    "                      (ds.longitude >= LON_RANGE[0]) &\\\n",
    "                      (ds.longitude <= LON_RANGE[1]),\n",
    "                      drop=True)\\\n",
    "                      .to_dataframe().reset_index().dropna().drop(labels=[\"time\", ], axis=1)\n",
    "        ds = ds.groupby([\"latitude\", \"longitude\", \"month\", \"year\"]).mean().reset_index()\n",
    "\n",
    "        climatology_df = climatology_df.merge(ds, how=\"left\", on=[\"day_of_year\", \"latitude\", \"longitude\"])\\\n",
    "                .drop(labels=[\"day_of_year\"], axis=1)\n",
    "\n",
    "        climatology_df[\"temperature\"] += climatology_df[\"climatology\"] \n",
    "        climatology_df.drop(labels=[\"climatology\"], axis=1, inplace=True)\n",
    "        climatology_df.rename(columns={\"temperature\":\"temperature\"+suffixes[data_i]}, inplace=True)  \n",
    "        \n",
    "        datasets.append(climatology_df.dropna())\n",
    "\n",
    "    datasets = pd.concat(datasets, ignore_index=True)    \n",
    "    temperature_dfs.append(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551fe4a0",
   "metadata": {},
   "source": [
    "We combine min, max and avg temperature data as separate columns in a single dataframe by latitude, longitude, month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25b8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp_df = reduce(lambda df_left,df_right: pd.merge(df_left, df_right, \n",
    "                                              on=[\"latitude\", \"longitude\", \"month\", \"year\"], \n",
    "                                              how='left'), \n",
    "                  temperature_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcebb827",
   "metadata": {},
   "source": [
    "## Export\n",
    "We are exporting the temperature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b1cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp_df.to_csv(\"../data/processed_data/temperatures.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
